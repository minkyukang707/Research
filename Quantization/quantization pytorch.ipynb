{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training static quantization (Pytorch) - ResNet18\n",
    "In this notebook, you will be able to see how quantization in PyTorch can result in significant decreases in model size while increasing speed. Note that quantization is currently only supported for CPUs, so we will be utilizing GPUs / CUDA only for training and CPU for testing.\n",
    "Furthermore, while using complex dataset the accuracy might decrease upon quantization. By using a quantization configuration\n",
    "\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "we can significantly improve on the accuracy. We repeat the same exercise with the recommended configuration for quantizing for x86 architectures. This configuration does the following:\n",
    "1. Quantizes weights on a per-channel basis\n",
    "2. Uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "              batch_size=64, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 model\n",
    "This code is taken from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
    "\n",
    "> NOTE: Training uses resnet model as is with addition operation and floating point inputs / outputs.      \n",
    "But when model is quantized while testing addition operation is replaced with FloatFunction and the inputs         / outputs are quantized/dequantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        groups: Number of blocked connections from input channels to output channels. Default: 1\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=3, with specified out_planes\n",
    "    \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=1, with specified out_planes\n",
    "        \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, mnist=False, quantize=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if mnist:\n",
    "            num_channels = 1\n",
    "        else:\n",
    "            num_channels = 3\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead.\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer, quantize=self.quantize))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, quantize=self.quantize))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # Input are quantized\n",
    "        if self.quantize:\n",
    "            x = self.quant(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Outputs are dequantized\n",
    "        if self.quantize:\n",
    "            x = self.dequant(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "         # See note [TorchScript super()]\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\" Train the model with given dataset\n",
    "    \n",
    "    Args:\n",
    "        args: args like log interval\n",
    "        model: ResNet model to train\n",
    "        device: CPU/GPU\n",
    "        train_loader: dataset iterator\n",
    "        optimizer: optimizer to update weights\n",
    "        epoch: number of epochs to train for\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.621168\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.018376\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.013803\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.020921\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.046167\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.005177\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.012947\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.029640\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001139\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.001206\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, quantize=False, fbgemm=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        modules_to_fuse = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2']]\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse)\n",
    "        if fbgemm:\n",
    "            model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        else:\n",
    "            model.qconfig = torch.quantization.default_qconfig\n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance - unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 44.759591\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Elapsed time = 15.0568 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.11016496270895004, zero_point=61, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10224931687116623, zero_point=55, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10670270025730133, zero_point=67, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.1430341601371765, zero_point=48)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.11084137111902237, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10498251020908356, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.16973379254341125, zero_point=39)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.10595948249101639, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1021081879734993, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.12286768108606339, zero_point=62)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.1736087203025818, zero_point=58)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.0999017134308815, zero_point=59, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09808696806430817, zero_point=66, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.15558238327503204, zero_point=37)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.10151470452547073, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08093071728944778, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.11250447481870651, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.13991950452327728, zero_point=60)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08513453602790833, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08258720487356186, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.12554164230823517, zero_point=40)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.08223091065883636, zero_point=67, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08285616338253021, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.08519431203603745, zero_point=67)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.12057787925004959, zero_point=61)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08568473905324936, zero_point=66, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08993765711784363, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.12852446734905243, zero_point=42)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.2206566333770752, zero_point=35, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 11.201645\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 9926/10000 (99%)\n",
      "\n",
      "Elapsed time = 3.6423 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader, quantize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
