{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Install packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-win_amd64.whl (8.3 MB)\n",
      "     ---------------------------------------- 8.3/8.3 MB 9.0 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "     ---------------------------------------- 42.2/42.2 MB 7.4 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ------------------------------------- 298.0/298.0 kB 18.0 MB/s eta 0:00:00\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ydata-profiling 4.0.0 requires htmlmin==0.1.12, which is not installed.\n",
      "ydata-profiling 4.0.0 requires matplotlib<3.7,>=3.2, which is not installed.\n",
      "ydata-profiling 4.0.0 requires pandas!=1.4.0,<1.6,>1.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires pydantic<1.11,>=1.8.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires seaborn<0.13,>=0.10.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires typeguard<2.14,>=2.13.2, which is not installed.\n",
      "statsmodels 0.13.5 requires pandas>=0.25, which is not installed.\n",
      "pynndescent 0.5.5 requires llvmlite>=0.30, which is not installed.\n",
      "phik 0.12.3 requires matplotlib>=2.2.3, which is not installed.\n",
      "phik 0.12.3 requires pandas>=0.25.1, which is not installed.\n",
      "librosa 0.10.0 requires lazy-loader>=0.1, which is not installed.\n",
      "librosa 0.10.0 requires msgpack>=1.0, which is not installed.\n",
      "librosa 0.10.0 requires soundfile>=0.12.1, which is not installed.\n",
      "librosa 0.10.0 requires soxr>=0.3.2, which is not installed.\n",
      "imagehash 4.3.1 requires PyWavelets, which is not installed.\n",
      "gensim 4.2.0 requires smart-open>=1.8.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\n",
      "ydata-profiling 4.0.0 requires scipy<1.10,>=1.4.1, but you have scipy 1.10.1 which is incompatible.\n",
      "ydata-profiling 4.0.0 requires tqdm<4.65,>=4.48.2, but you have tqdm 4.65.0 which is incompatible.\n",
      "optuna 3.0.3 requires scipy<1.9.0,>=1.7.0, but you have scipy 1.10.1 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting install\n",
      "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
      "Collecting torch==1.8.1+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.8.1%2Bcpu-cp38-cp38-win_amd64.whl (190.5 MB)\n",
      "     -------------------------------------- 190.5/190.5 MB 7.4 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.9.1+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.9.1%2Bcpu-cp38-cp38-win_amd64.whl (845 kB)\n",
      "     ------------------------------------- 845.3/845.3 kB 52.2 MB/s eta 0:00:00\n",
      "Collecting torchaudio===0.8.1\n",
      "  Downloading torchaudio-0.8.1-cp38-none-win_amd64.whl (109 kB)\n",
      "     ---------------------------------------- 109.3/109.3 kB ? eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.3-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 14.9/14.9 MB 8.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch==1.8.1+cpu) (4.5.0)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading Pillow-9.5.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 17.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow, numpy, install, torch, torchvision, torchaudio\n",
      "Successfully installed install-1.3.5 numpy-1.24.3 pillow-9.5.0 torch-1.8.1+cpu torchaudio-0.8.1 torchvision-0.9.1+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ydata-profiling 4.0.0 requires htmlmin==0.1.12, which is not installed.\n",
      "ydata-profiling 4.0.0 requires matplotlib<3.7,>=3.2, which is not installed.\n",
      "ydata-profiling 4.0.0 requires pandas!=1.4.0,<1.6,>1.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires pydantic<1.11,>=1.8.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires PyYAML<6.1,>=5.0.0, which is not installed.\n",
      "ydata-profiling 4.0.0 requires scipy<1.10,>=1.4.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires seaborn<0.13,>=0.10.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires tqdm<4.65,>=4.48.2, which is not installed.\n",
      "ydata-profiling 4.0.0 requires typeguard<2.14,>=2.13.2, which is not installed.\n",
      "visions 0.7.5 requires networkx>=2.4, which is not installed.\n",
      "visions 0.7.5 requires pandas>=0.25.3, which is not installed.\n",
      "visions 0.7.5 requires tangled-up-in-unicode>=0.0.4, which is not installed.\n",
      "statsmodels 0.13.5 requires pandas>=0.25, which is not installed.\n",
      "statsmodels 0.13.5 requires scipy>=1.3; (python_version > \"3.9\" or platform_system != \"Windows\" or platform_machine != \"x86\") and python_version < \"3.12\", which is not installed.\n",
      "phik 0.12.3 requires joblib>=0.14.1, which is not installed.\n",
      "phik 0.12.3 requires matplotlib>=2.2.3, which is not installed.\n",
      "phik 0.12.3 requires pandas>=0.25.1, which is not installed.\n",
      "phik 0.12.3 requires scipy>=1.5.2, which is not installed.\n",
      "optuna 3.0.3 requires PyYAML, which is not installed.\n",
      "optuna 3.0.3 requires scipy<1.9.0,>=1.7.0, which is not installed.\n",
      "optuna 3.0.3 requires tqdm, which is not installed.\n",
      "numba 0.56.4 requires llvmlite<0.40,>=0.39.0dev0, which is not installed.\n",
      "mujoco 2.3.2 requires absl-py, which is not installed.\n",
      "mujoco 2.3.2 requires glfw, which is not installed.\n",
      "mujoco 2.3.2 requires pyopengl, which is not installed.\n",
      "librosa 0.10.0 requires joblib>=0.14, which is not installed.\n",
      "librosa 0.10.0 requires lazy-loader>=0.1, which is not installed.\n",
      "librosa 0.10.0 requires msgpack>=1.0, which is not installed.\n",
      "librosa 0.10.0 requires scikit-learn>=0.20.0, which is not installed.\n",
      "librosa 0.10.0 requires scipy>=1.2.0, which is not installed.\n",
      "librosa 0.10.0 requires soundfile>=0.12.1, which is not installed.\n",
      "librosa 0.10.0 requires soxr>=0.3.2, which is not installed.\n",
      "imbalanced-learn 0.9.0 requires joblib>=0.11, which is not installed.\n",
      "imbalanced-learn 0.9.0 requires scikit-learn>=1.0.1, which is not installed.\n",
      "imbalanced-learn 0.9.0 requires scipy>=1.1.0, which is not installed.\n",
      "imbalanced-learn 0.9.0 requires threadpoolctl>=2.0.0, which is not installed.\n",
      "imagehash 4.3.1 requires PyWavelets, which is not installed.\n",
      "imagehash 4.3.1 requires scipy, which is not installed.\n",
      "gensim 4.2.0 requires scipy>=0.18.1, which is not installed.\n",
      "gensim 4.2.0 requires smart-open>=1.8.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting onnxruntime==1.7.0\n",
      "  Downloading onnxruntime-1.7.0-cp38-cp38-win_amd64.whl (4.4 MB)\n",
      "     ---------------------------------------- 4.4/4.4 MB 6.5 MB/s eta 0:00:00\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.22.3-cp38-cp38-win_amd64.whl (420 kB)\n",
      "     ---------------------------------------- 420.6/420.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from onnxruntime==1.7.0) (1.24.3)\n",
      "Installing collected packages: protobuf, onnxruntime\n",
      "Successfully installed onnxruntime-1.7.0 protobuf-4.22.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting onnxruntime-tools\n",
      "  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
      "     -------------------------------------- 212.7/212.7 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting onnx\n",
      "  Downloading onnx-1.13.1-cp38-cp38-win_amd64.whl (12.2 MB)\n",
      "     ---------------------------------------- 12.2/12.2 MB 7.9 MB/s eta 0:00:00\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting py3nvml\n",
      "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.5/55.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from onnxruntime-tools) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from onnxruntime-tools) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from onnxruntime-tools) (5.9.3)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB ? eta 0:00:00\n",
      "Collecting protobuf<4,>=3.20.2\n",
      "  Downloading protobuf-3.20.3-cp38-cp38-win_amd64.whl (904 kB)\n",
      "     ---------------------------------------- 904.4/904.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from onnx->onnxruntime-tools) (4.5.0)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB ? eta 0:00:00\n",
      "Installing collected packages: pyreadline3, py-cpuinfo, xmltodict, protobuf, humanfriendly, py3nvml, onnx, coloredlogs, onnxruntime-tools\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.22.3\n",
      "    Uninstalling protobuf-4.22.3:\n",
      "      Successfully uninstalled protobuf-4.22.3\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.13.1 onnxruntime-tools-1.7.0 protobuf-3.20.3 py-cpuinfo-9.0.0 py3nvml-0.2.7 pyreadline3-3.4.1 xmltodict-0.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cmd2 2.4.2 requires pyperclip>=1.6, which is not installed.\n",
      "cliff 4.0.0 requires PyYAML>=3.12, which is not installed.\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 9.4 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "     ---------------------------------------- 155.4/155.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.3.23-cp38-cp38-win_amd64.whl (267 kB)\n",
      "     ---------------------------------------- 267.9/267.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from transformers) (23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     ---------------------------------------- 224.5/224.5 kB ? eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 11.6 MB/s eta 0:00:00\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "     -------------------------------------- 154.0/154.0 kB 9.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: tokenizers, tqdm, regex, pyyaml, fsspec, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.0 fsspec-2023.4.0 huggingface-hub-0.14.1 pyyaml-6.0 regex-2023.3.23 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ydata-profiling 4.0.0 requires htmlmin==0.1.12, which is not installed.\n",
      "ydata-profiling 4.0.0 requires matplotlib<3.7,>=3.2, which is not installed.\n",
      "ydata-profiling 4.0.0 requires pandas!=1.4.0,<1.6,>1.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires pydantic<1.11,>=1.8.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires scipy<1.10,>=1.4.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires seaborn<0.13,>=0.10.1, which is not installed.\n",
      "ydata-profiling 4.0.0 requires typeguard<2.14,>=2.13.2, which is not installed.\n",
      "optuna 3.0.3 requires scipy<1.9.0,>=1.7.0, which is not installed.\n",
      "ydata-profiling 4.0.0 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\n",
      "ydata-profiling 4.0.0 requires tqdm<4.65,>=4.48.2, but you have tqdm 4.65.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnx in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (1.13.1)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from onnx) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from onnx) (1.24.3)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post4-py3-none-any.whl size=2969 sha256=19e209383f69d67e316f52311a60450b3bb699538e467b3b5050c0ac852e690d\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-zrieqe_4\\wheels\\84\\3f\\80\\e49971719e76c0387733de7973744b4b19b01dc14afcce8829\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0.post4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!{sys.executable} -m pip install --upgrade onnxruntime==1.7.0\n",
    "!{sys.executable} -m pip install --upgrade onnxruntime-tools\n",
    "\n",
    "# Install other packages used in this notebook.\n",
    "!{sys.executable} -m pip install --upgrade transformers\n",
    "!{sys.executable} -m pip install --upgrade onnx sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Download GLUE data and Fine-tune BERT model for MPRC task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n",
      "python: can't open file 'download_glue_data.py': [Errno 2] No such file or directory\n",
      "'ls'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0  386M    0 50695    0     0  33417      0  3:22:10  0:00:01  3:22:09 33417\n",
      "  1  386M    1 4536k    0     0  1833k      0  0:03:35  0:00:02  0:03:33 1833k\n",
      "  3  386M    3 11.6M    0     0  3438k      0  0:01:55  0:00:03  0:01:52 3438k\n",
      "  4  386M    4 18.7M    0     0  4315k      0  0:01:31  0:00:04  0:01:27 4314k\n",
      "  6  386M    6 25.9M    0     0  4866k      0  0:01:21  0:00:05  0:01:16 6184k\n",
      "  8  386M    8 33.1M    0     0  5254k      0  0:01:15  0:00:06  0:01:09 6855k\n",
      " 10  386M   10 40.3M    0     0  5534k      0  0:01:11  0:00:07  0:01:04 7371k\n",
      " 12  386M   12 47.5M    0     0  5750k      0  0:01:08  0:00:08  0:01:00 7350k\n",
      " 14  386M   14 54.6M    0     0  5919k      0  0:01:06  0:00:09  0:00:57 7349k\n",
      " 16  386M   16 61.8M    0     0  6056k      0  0:01:05  0:00:10  0:00:55 7354k\n",
      " 17  386M   17 69.0M    0     0  6168k      0  0:01:04  0:00:11  0:00:53 7351k\n",
      " 19  386M   19 76.1M    0     0  6262k      0  0:01:03  0:00:12  0:00:51 7350k\n",
      " 21  386M   21 83.3M    0     0  6344k      0  0:01:02  0:00:13  0:00:49 7349k\n",
      " 23  386M   23 90.5M    0     0  6414k      0  0:01:01  0:00:14  0:00:47 7348k\n",
      " 25  386M   25 97.7M    0     0  6474k      0  0:01:01  0:00:15  0:00:46 7348k\n",
      " 27  386M   27  104M    0     0  6527k      0  0:01:00  0:00:16  0:00:44 7350k\n",
      " 28  386M   28  112M    0     0  6575k      0  0:01:00  0:00:17  0:00:43 7353k\n",
      " 30  386M   30  119M    0     0  6617k      0  0:00:59  0:00:18  0:00:41 7350k\n",
      " 32  386M   32  126M    0     0  6655k      0  0:00:59  0:00:19  0:00:40 7352k\n",
      " 34  386M   34  133M    0     0  6688k      0  0:00:59  0:00:20  0:00:39 7352k\n",
      " 36  386M   36  140M    0     0  6718k      0  0:00:58  0:00:21  0:00:37 7346k\n",
      " 38  386M   38  147M    0     0  6747k      0  0:00:58  0:00:22  0:00:36 7348k\n",
      " 40  386M   40  155M    0     0  6773k      0  0:00:58  0:00:23  0:00:35 7351k\n",
      " 42  386M   42  162M    0     0  6797k      0  0:00:58  0:00:24  0:00:34 7350k\n",
      " 43  386M   43  169M    0     0  6816k      0  0:00:58  0:00:25  0:00:33 7339k\n",
      " 45  386M   45  176M    0     0  6781k      0  0:00:58  0:00:26  0:00:32 7041k\n",
      " 47  386M   47  183M    0     0  6858k      0  0:00:57  0:00:27  0:00:30 7355k\n",
      " 49  386M   49  191M    0     0  6874k      0  0:00:57  0:00:28  0:00:29 7348k\n",
      " 51  386M   51  198M    0     0  6890k      0  0:00:57  0:00:29  0:00:28 7345k\n",
      " 53  386M   53  205M    0     0  6906k      0  0:00:57  0:00:30  0:00:27 7364k\n",
      " 54  386M   54  212M    0     0  6920k      0  0:00:57  0:00:31  0:00:26 7682k\n",
      " 56  386M   56  219M    0     0  6933k      0  0:00:57  0:00:32  0:00:25 7348k\n",
      " 58  386M   58  226M    0     0  6946k      0  0:00:56  0:00:33  0:00:23 7354k\n",
      " 60  386M   60  234M    0     0  6957k      0  0:00:56  0:00:34  0:00:22 7348k\n",
      " 62  386M   62  241M    0     0  6968k      0  0:00:56  0:00:35  0:00:21 7348k\n",
      " 64  386M   64  248M    0     0  6979k      0  0:00:56  0:00:36  0:00:20 7345k\n",
      " 66  386M   66  255M    0     0  6989k      0  0:00:56  0:00:37  0:00:19 7349k\n",
      " 67  386M   67  262M    0     0  6998k      0  0:00:56  0:00:38  0:00:18 7348k\n",
      " 69  386M   69  270M    0     0  7007k      0  0:00:56  0:00:39  0:00:17 7354k\n",
      " 71  386M   71  277M    0     0  7016k      0  0:00:56  0:00:40  0:00:16 7352k\n",
      " 73  386M   73  284M    0     0  7024k      0  0:00:56  0:00:41  0:00:15 7352k\n",
      " 75  386M   75  291M    0     0  7031k      0  0:00:56  0:00:42  0:00:14 7352k\n",
      " 77  386M   77  298M    0     0  7039k      0  0:00:56  0:00:43  0:00:13 7348k\n",
      " 79  386M   79  305M    0     0  7046k      0  0:00:56  0:00:44  0:00:12 7350k\n",
      " 80  386M   80  313M    0     0  7052k      0  0:00:56  0:00:45  0:00:11 7349k\n",
      " 82  386M   82  320M    0     0  7058k      0  0:00:56  0:00:46  0:00:10 7347k\n",
      " 84  386M   84  327M    0     0  7065k      0  0:00:56  0:00:47  0:00:09 7348k\n",
      " 86  386M   86  333M    0     0  7042k      0  0:00:56  0:00:48  0:00:08 7071k\n",
      " 88  386M   88  341M    0     0  7076k      0  0:00:55  0:00:49  0:00:06 7348k\n",
      " 90  386M   90  348M    0     0  7081k      0  0:00:55  0:00:50  0:00:05 7341k\n",
      " 92  386M   92  356M    0     0  7087k      0  0:00:55  0:00:51  0:00:04 7351k\n",
      " 93  386M   93  363M    0     0  7092k      0  0:00:55  0:00:52  0:00:03 7348k\n",
      " 95  386M   95  370M    0     0  7097k      0  0:00:55  0:00:53  0:00:02 7639k\n",
      " 97  386M   97  377M    0     0  7101k      0  0:00:55  0:00:54  0:00:01 7350k\n",
      " 99  386M   99  384M    0     0  7106k      0  0:00:55  0:00:55 --:--:-- 7360k\n",
      "100  386M  100  386M    0     0  7106k      0  0:00:55  0:00:55 --:--:-- 7343k\n",
      "'unzip'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/huggingface/transformers/.../utils/download_glue_data.py\n",
    "!python download_glue_data.py --data_dir='glue_data' --tasks='MRPC'\n",
    "!ls glue_data/MRPC\n",
    "!curl https://download.pytorch.org/tutorial/MRPC.zip --output MPRC.zip\n",
    "!unzip -n MPRC.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  386M    0 15886    0     0   8884      0 12:40:28  0:00:01 12:40:27  8889\n",
      "  0  386M    0 3203k    0     0  1602k      0  0:04:07  0:00:01  0:04:06 1602k\n",
      "  2  386M    2 10.2M    0     0  3506k      0  0:01:52  0:00:02  0:01:50 3505k\n",
      "  4  386M    4 17.4M    0     0  4467k      0  0:01:28  0:00:03  0:01:25 4466k\n",
      "  6  386M    6 24.5M    0     0  5042k      0  0:01:18  0:00:04  0:01:14 5041k\n",
      "  8  386M    8 31.7M    0     0  5428k      0  0:01:12  0:00:05  0:01:07 7732k\n",
      " 10  386M   10 38.9M    0     0  5705k      0  0:01:09  0:00:06  0:01:03 7347k\n",
      " 11  386M   11 46.1M    0     0  5911k      0  0:01:06  0:00:07  0:00:59 7351k\n",
      " 13  386M   13 53.3M    0     0  6070k      0  0:01:05  0:00:08  0:00:57 7351k\n",
      " 15  386M   15 60.5M    0     0  6204k      0  0:01:03  0:00:09  0:00:54 7364k\n",
      " 17  386M   17 67.7M    0     0  6303k      0  0:01:02  0:00:11  0:00:51 7351k\n",
      " 19  386M   19 74.8M    0     0  6392k      0  0:01:01  0:00:11  0:00:50 7355k\n",
      " 21  386M   21 82.0M    0     0  6466k      0  0:01:01  0:00:12  0:00:49 7353k\n",
      " 23  386M   23 89.2M    0     0  6528k      0  0:01:00  0:00:13  0:00:47 7353k\n",
      " 24  386M   24 96.4M    0     0  6583k      0  0:01:00  0:00:14  0:00:46 7342k\n",
      " 26  386M   26  103M    0     0  6630k      0  0:00:59  0:00:15  0:00:44 7349k\n",
      " 28  386M   28  110M    0     0  6672k      0  0:00:59  0:00:16  0:00:43 7343k\n",
      " 30  386M   30  117M    0     0  6711k      0  0:00:58  0:00:17  0:00:41 7345k\n",
      " 32  386M   32  125M    0     0  6743k      0  0:00:58  0:00:18  0:00:40 7342k\n",
      " 34  386M   34  132M    0     0  6774k      0  0:00:58  0:00:19  0:00:39 7345k\n",
      " 36  386M   36  139M    0     0  6801k      0  0:00:58  0:00:20  0:00:38 7346k\n",
      " 37  386M   37  146M    0     0  6826k      0  0:00:57  0:00:21  0:00:36 7347k\n",
      " 39  386M   39  153M    0     0  6849k      0  0:00:57  0:00:22  0:00:35 7347k\n",
      " 41  386M   41  160M    0     0  6869k      0  0:00:57  0:00:23  0:00:34 7351k\n",
      " 43  386M   43  168M    0     0  6889k      0  0:00:57  0:00:24  0:00:33 7350k\n",
      " 45  386M   45  174M    0     0  6849k      0  0:00:57  0:00:26  0:00:31 7051k\n",
      " 47  386M   47  182M    0     0  6923k      0  0:00:57  0:00:26  0:00:31 7351k\n",
      " 49  386M   49  189M    0     0  6938k      0  0:00:57  0:00:27  0:00:30 7349k\n",
      " 50  386M   50  196M    0     0  6952k      0  0:00:56  0:00:28  0:00:28 7349k\n",
      " 52  386M   52  204M    0     0  6965k      0  0:00:56  0:00:29  0:00:27 7347k\n",
      " 54  386M   54  211M    0     0  6978k      0  0:00:56  0:00:30  0:00:26 7651k\n",
      " 56  386M   56  218M    0     0  6989k      0  0:00:56  0:00:31  0:00:25 7348k\n",
      " 58  386M   58  225M    0     0  7001k      0  0:00:56  0:00:32  0:00:24 7350k\n",
      " 60  386M   60  232M    0     0  7011k      0  0:00:56  0:00:33  0:00:23 7350k\n",
      " 62  386M   62  239M    0     0  7020k      0  0:00:56  0:00:34  0:00:22 7349k\n",
      " 63  386M   63  247M    0     0  7030k      0  0:00:56  0:00:35  0:00:21 7350k\n",
      " 65  386M   65  254M    0     0  7038k      0  0:00:56  0:00:36  0:00:20 7352k\n",
      " 67  386M   67  261M    0     0  7046k      0  0:00:56  0:00:37  0:00:19 7348k\n",
      " 69  386M   69  268M    0     0  7054k      0  0:00:56  0:00:38  0:00:18 7351k\n",
      " 71  386M   71  275M    0     0  7061k      0  0:00:56  0:00:39  0:00:17 7347k\n",
      " 73  386M   73  282M    0     0  7069k      0  0:00:55  0:00:40  0:00:15 7349k\n",
      " 75  386M   75  290M    0     0  7075k      0  0:00:55  0:00:42  0:00:13 7347k\n",
      " 76  386M   76  297M    0     0  7081k      0  0:00:55  0:00:42  0:00:13 7347k\n",
      " 78  386M   78  304M    0     0  7087k      0  0:00:55  0:00:43  0:00:12 7348k\n",
      " 80  386M   80  311M    0     0  7093k      0  0:00:55  0:00:44  0:00:11 7352k\n",
      " 82  386M   82  318M    0     0  7099k      0  0:00:55  0:00:45  0:00:10 7352k\n",
      " 84  386M   84  326M    0     0  7104k      0  0:00:55  0:00:46  0:00:09 7352k\n",
      " 86  386M   86  333M    0     0  7110k      0  0:00:55  0:00:47  0:00:08 7351k\n",
      " 88  386M   88  340M    0     0  7115k      0  0:00:55  0:00:48  0:00:07 7353k\n",
      " 89  386M   89  347M    0     0  7119k      0  0:00:55  0:00:49  0:00:06 7351k\n",
      " 91  386M   91  354M    0     0  7124k      0  0:00:55  0:00:50  0:00:05 7349k\n",
      " 93  386M   93  361M    0     0  7128k      0  0:00:55  0:00:51  0:00:04 7349k\n",
      " 95  386M   95  369M    0     0  7132k      0  0:00:55  0:00:52  0:00:03 7346k\n",
      " 97  386M   97  376M    0     0  7136k      0  0:00:55  0:00:53  0:00:02 7342k\n",
      " 99  386M   99  383M    0     0  7140k      0  0:00:55  0:00:54  0:00:01 7346k\n",
      "100  386M  100  386M    0     0  7142k      0  0:00:55  0:00:55 --:--:-- 7349k\n",
      "'unzip'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "!curl https://download.pytorch.org/tutorial/MRPC.zip --output MPRC.zip\n",
    "!unzip -n MPRC.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load and quantize model with PyTorch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Import modules and set global configurations\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\processors\\glue.py:174: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from tqdm import tqdm\n",
    "from transformers import (BertConfig, BertForSequenceClassification, BertTokenizer,)\n",
    "from transformers import glue_compute_metrics as compute_metrics\n",
    "from transformers import glue_output_modes as output_modes\n",
    "from transformers import glue_processors as processors\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "\n",
    "# Setup warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    category=DeprecationWarning,\n",
    "    module=r'.*'\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    action='default',\n",
    "    module=r'torch.quantization'\n",
    ")\n",
    "\n",
    "# Setup logging level to WARN. Change it accordingly\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.WARN)\n",
    "\n",
    "#logging.getLogger(\"transformers.modeling_utils\").setLevel(\n",
    "#    logging.WARN)  # Reduce logging\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "\n",
    "configs = Namespace()\n",
    "\n",
    "# The output directory for the fine-tuned model, $OUT_DIR.\n",
    "configs.output_dir = \"./MRPC/\" # 튜닝모델 저장 폴더 \n",
    "\n",
    "# The data directory for the MRPC task in the GLUE benchmark, $GLUE_DIR/$TASK_NAME.\n",
    "configs.data_dir = \"./glue_data/MRPC\" # 데이터셋 폴더 \n",
    "\n",
    "# The model name or path for the pre-trained model.\n",
    "configs.model_name_or_path = \"bert-base-uncased\" # 모델이름 \n",
    "# The maximum length of an input sequence\n",
    "configs.max_seq_length = 128 # 입력 시퀀스 최대 길이 \n",
    "\n",
    "# Prepare GLUE task.\n",
    "configs.task_name = \"MRPC\".lower() \n",
    "configs.processor = processors[configs.task_name]()\n",
    "configs.output_mode = output_modes[configs.task_name]\n",
    "configs.label_list = configs.processor.get_labels()\n",
    "configs.model_type = \"bert\".lower()\n",
    "configs.do_lower_case = True\n",
    "\n",
    "# Set the device, batch size, topology, and caching flags.\n",
    "configs.device = \"cpu\" # 디바이스 타입 \n",
    "configs.eval_batch_size = 1\n",
    "configs.n_gpu = 0\n",
    "configs.local_rank = -1\n",
    "configs.overwrite_cache = False\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Load and quantize the fine-tuned BERT model with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 417.73052883148193\n",
      "Size (MB): 173.0947561264038\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = BertForSequenceClassification.from_pretrained(configs.output_dir)\n",
    "model.to(configs.device)\n",
    "\n",
    "# quantize model\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "#print(quantized_model)\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/(1024*1024))\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(model)\n",
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Evaluate the accuracy and performance of PyTorch quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\processors\\glue.py:174: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating PyTorch full precision accuracy and performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 408/408 [00:50<00:00,  8.09it/s]\n",
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\metrics\\__init__.py:61: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\metrics\\__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\metrics\\__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\processors\\glue.py:174: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8602941176470589, 'f1': 0.9018932874354562, 'acc_and_f1': 0.8810937025412575}\n",
      "Evaluate total time (seconds): 50.5\n",
      "Evaluating PyTorch quantization accuracy and performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 408/408 [00:34<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8529411764705882, 'f1': 0.8958333333333334, 'acc_and_f1': 0.8743872549019608}\n",
      "Evaluate total time (seconds): 34.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\metrics\\__init__.py:61: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\metrics\\__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "c:\\Users\\user\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\transformers\\data\\metrics\\__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the 🤗 Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
    "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "def evaluate(args, model, tokenizer, prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_task_names = (\"mnli\", \"mnli-mm\") if args.task_name == \"mnli\" else (args.task_name,)\n",
    "    eval_outputs_dirs = (args.output_dir, args.output_dir + '-MM') if args.task_name == \"mnli\" else (args.output_dir,)\n",
    "\n",
    "    results = {}\n",
    "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
    "        eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)\n",
    "\n",
    "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
    "            os.makedirs(eval_output_dir)\n",
    "\n",
    "        # Note that DistributedSampler samples randomly\n",
    "        eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
    "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "        # multi-gpu eval\n",
    "        if args.n_gpu > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            model.eval()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = {'input_ids':      batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'labels':         batch[3]}\n",
    "                if args.model_type != 'distilbert':\n",
    "                    inputs['token_type_ids'] = batch[2] if args.model_type in ['bert', 'xlnet'] else None  # XLM, DistilBERT and RoBERTa don't use segment_ids\n",
    "                outputs = model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        if args.output_mode == \"classification\":\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "        elif args.output_mode == \"regression\":\n",
    "            preds = np.squeeze(preds)\n",
    "        result = compute_metrics(eval_task, preds, out_label_ids)\n",
    "        results.update(result)\n",
    "\n",
    "        output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
    "        with open(output_eval_file, \"w\") as writer:\n",
    "            logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "            for key in sorted(result.keys()):\n",
    "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def load_and_cache_examples(args, task, tokenizer, evaluate=False):\n",
    "    if args.local_rank not in [-1, 0] and not evaluate:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
    "\n",
    "    processor = processors[task]()\n",
    "    output_mode = output_modes[task]\n",
    "    # Load data features from cache or dataset file\n",
    "    cached_features_file = os.path.join(args.data_dir, 'cached_{}_{}_{}_{}'.format(\n",
    "        'dev' if evaluate else 'train',\n",
    "        list(filter(None, args.model_name_or_path.split('/'))).pop(),\n",
    "        str(args.max_seq_length),\n",
    "        str(task)))\n",
    "    if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
    "        label_list = processor.get_labels()\n",
    "        if task in ['mnli', 'mnli-mm'] and args.model_type in ['roberta']:\n",
    "            # HACK(label indices are swapped in RoBERTa pretrained model)\n",
    "            label_list[1], label_list[2] = label_list[2], label_list[1]\n",
    "        examples = processor.get_dev_examples(args.data_dir) if evaluate else processor.get_train_examples(args.data_dir)\n",
    "        features = convert_examples_to_features(examples,\n",
    "                                                tokenizer,\n",
    "                                                label_list=label_list,\n",
    "                                                max_length=args.max_seq_length,\n",
    "                                                output_mode=output_mode,\n",
    "        )\n",
    "        if args.local_rank in [-1, 0]:\n",
    "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "            torch.save(features, cached_features_file)\n",
    "\n",
    "    if args.local_rank == 0 and not evaluate:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    if output_mode == \"classification\":\n",
    "        all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_labels = torch.tensor([f.label for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "    return dataset\n",
    "\n",
    "def time_model_evaluation(model, configs, tokenizer):\n",
    "    eval_start_time = time.time()\n",
    "    result = evaluate(configs, model, tokenizer, prefix=\"\")\n",
    "    eval_end_time = time.time()\n",
    "    eval_duration_time = eval_end_time - eval_start_time\n",
    "    print(result)\n",
    "    print(\"Evaluate total time (seconds): {0:.1f}\".format(eval_duration_time))\n",
    "\n",
    "# define the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    configs.output_dir, do_lower_case=configs.do_lower_case)\n",
    "    \n",
    "# Evaluate the original FP32 BERT model\n",
    "print('Evaluating PyTorch full precision accuracy and performance:')\n",
    "time_model_evaluation(model, configs, tokenizer)\n",
    "\n",
    "# Evaluate the INT8 BERT model after the dynamic quantization\n",
    "print('Evaluating PyTorch quantization accuracy and performance:')\n",
    "time_model_evaluation(quantized_model, configs, tokenizer)\n",
    "\n",
    "# Serialize the quantized model\n",
    "quantized_output_dir = configs.output_dir + \"quantized/\"\n",
    "if not os.path.exists(quantized_output_dir):\n",
    "    os.makedirs(quantized_output_dir)\n",
    "    quantized_model.save_pretrained(quantized_output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quantization and Inference with ORT\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Export to ONNX model and optimize with ONNXRuntime-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "def export_onnx_model(args, model, tokenizer, onnx_model_path):\n",
    "    with torch.no_grad():\n",
    "        inputs = {'input_ids':      torch.ones(1,128, dtype=torch.int64),\n",
    "                    'attention_mask': torch.ones(1,128, dtype=torch.int64),\n",
    "                    'token_type_ids': torch.ones(1,128, dtype=torch.int64)}\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        symbolic_names = {0: 'batch_size', 1: 'max_seq_len'}\n",
    "        torch.onnx.export(model,                                      # model being run\n",
    "                    (inputs['input_ids'],                             # model input (or a tuple for multiple inputs)\n",
    "                    inputs['attention_mask'], \n",
    "                    inputs['token_type_ids']),                        # model input (or a tuple for multiple inputs)\n",
    "                    onnx_model_path,                                  # where to save the model (can be a file or file-like object)\n",
    "                    opset_version=11,                                 # the ONNX version to export the model to\n",
    "                    do_constant_folding=True,                         # whether to execute constant folding for optimization\n",
    "                    input_names=['input_ids',                         # the model's input names\n",
    "                                'input_mask', \n",
    "                                'segment_ids'],\n",
    "                    output_names=['output'],                          # the model's output names\n",
    "                    dynamic_axes={'input_ids': symbolic_names,        # variable length axes\n",
    "                                'input_mask' : symbolic_names,\n",
    "                                'segment_ids' : symbolic_names})\n",
    "        logger.info(\"ONNX Model exported to {0}\".format(onnx_model_path))\n",
    "\n",
    "export_onnx_model(configs, model, tokenizer, \"bert.onnx\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Quantize ONNX model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX full precision model size (MB): 417.69343852996826\n",
      "ONNX quantized model size (MB): 104.8716230392456\n"
     ]
    }
   ],
   "source": [
    "def quantize_onnx_model(onnx_model_path, quantized_model_path):\n",
    "    from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "    import onnx\n",
    "    onnx_opt_model = onnx.load(onnx_model_path)\n",
    "    quantize_dynamic(onnx_model_path,\n",
    "                     quantized_model_path,\n",
    "                     weight_type=QuantType.QInt8)\n",
    "\n",
    "    logger.info(f\"quantized model saved to:{quantized_model_path}\")\n",
    "\n",
    "quantize_onnx_model('bert_o1_cpu.onnx', 'bert.opt.quant.onnx')\n",
    "\n",
    "print('ONNX full precision model size (MB):', os.path.getsize(\"bert_o1_cpu.onnx\")/(1024*1024))\n",
    "print('ONNX quantized model size (MB):', os.path.getsize(\"bert.opt.quant.onnx\")/(1024*1024))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Evaluate ONNX quantization performance and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_onnx(args, model_path, tokenizer, prefix=\"\"):\n",
    "\n",
    "    sess_options = onnxruntime.SessionOptions()\n",
    "    sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    session = onnxruntime.InferenceSession(model_path, sess_options)\n",
    "\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_task_names = (\"mnli\", \"mnli-mm\") if args.task_name == \"mnli\" else (args.task_name,)\n",
    "    eval_outputs_dirs = (args.output_dir, args.output_dir + '-MM') if args.task_name == \"mnli\" else (args.output_dir,)\n",
    "\n",
    "    results = {}\n",
    "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
    "        eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)\n",
    "\n",
    "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
    "            os.makedirs(eval_output_dir)\n",
    "\n",
    "        # Note that DistributedSampler samples randomly\n",
    "        eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
    "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "        # multi-gpu eval\n",
    "        if args.n_gpu > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "        #eval_loss = 0.0\n",
    "        #nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(t.detach().cpu().numpy() for t in batch)\n",
    "            ort_inputs = {\n",
    "                                'input_ids':  batch[0],\n",
    "                                'input_mask': batch[1],\n",
    "                                'segment_ids': batch[2]\n",
    "                            }\n",
    "            logits = np.reshape(session.run(None, ort_inputs), (-1,2))\n",
    "            if preds is None:\n",
    "                preds = logits\n",
    "                #print(preds.shape)\n",
    "                out_label_ids = batch[3]\n",
    "            else:\n",
    "                preds = np.append(preds, logits, axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, batch[3], axis=0)\n",
    "\n",
    "        #print(preds.shap)\n",
    "        #eval_loss = eval_loss / nb_eval_steps\n",
    "        if args.output_mode == \"classification\":\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "        elif args.output_mode == \"regression\":\n",
    "            preds = np.squeeze(preds)\n",
    "        #print(preds)\n",
    "        #print(out_label_ids)\n",
    "        result = compute_metrics(eval_task, preds, out_label_ids)\n",
    "        results.update(result)\n",
    "\n",
    "        output_eval_file = os.path.join(eval_output_dir, prefix + \"_eval_results.txt\")\n",
    "        with open(output_eval_file, \"w\") as writer:\n",
    "            logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "            for key in sorted(result.keys()):\n",
    "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def time_ort_model_evaluation(model_path, configs, tokenizer, prefix=\"\"):\n",
    "    eval_start_time = time.time()\n",
    "    result = evaluate_onnx(configs, model_path, tokenizer, prefix=prefix)\n",
    "    eval_end_time = time.time()\n",
    "    eval_duration_time = eval_end_time - eval_start_time\n",
    "    print(result)\n",
    "    print(\"Evaluate total time (seconds): {0:.1f}\".format(eval_duration_time))\n",
    "\n",
    "print('Evaluating ONNXRuntime full precision accuracy and performance:')\n",
    "time_ort_model_evaluation('bert.opt.onnx', configs, tokenizer, \"onnx.opt\")\n",
    "    \n",
    "print('Evaluating ONNXRuntime quantization accuracy and performance:')\n",
    "time_ort_model_evaluation('bert.opt.quant.onnx', configs, tokenizer, \"onnx.opt.quant\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
