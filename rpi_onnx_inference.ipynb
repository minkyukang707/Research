{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX runtime Raspberry Pi 4 inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://onnxruntime.ai/docs/tutorials/iot-edge/rasp-pi-cv.html\n",
    "# 실행환경 : 라즈베리파이 (리눅스, Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/cassiebreviu/onnxruntime-raspberrypi.git # source code download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd onnxruntime-raspberrypi # 폴더로 이동 \n",
    "!pip install -r requirements.txt # requirements 설치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cameratest.py # 카메라 작동확인 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# camera test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Create test image using opencv.\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640) # set Width\n",
    "cap.set(4,480) # set Height\n",
    "\n",
    "ret, frame = cap.read()\n",
    "frame = cv2.flip(frame, -1) # Flip camera vertically\n",
    "cv2.imwrite('test.jpg', frame)\n",
    "\n",
    "# Start live video feed until `ESC` is pressed to quit.\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, -1) # Flip camera vertically\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('gray', gray)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: # press 'ESC' to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference on the Raspberry Pi with the inference_mobilenet.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path, height, width, channels=3):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((width, height), Image.LANCZOS)\n",
    "    image_data = np.asarray(image).astype(np.float32)\n",
    "    image_data = image_data.transpose([2, 0, 1]) # transpose to CHW\n",
    "    mean = np.array([0.079, 0.05, 0]) + 0.406\n",
    "    std = np.array([0.005, 0, 0.001]) + 0.224\n",
    "    for channel in range(image_data.shape[0]):\n",
    "        image_data[channel, :, :] = (image_data[channel, :, :] / 255 - mean[channel]) / std[channel]\n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    return image_data\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def run_sample(session, image_file, categories):\n",
    "    output = session.run([], {'input':preprocess_image(image_file, 224, 224)})[0]\n",
    "    output = output.flatten()\n",
    "    output = softmax(output) # this is optional\n",
    "    top5_catid = np.argsort(-output)[:5]\n",
    "    for catid in top5_catid:\n",
    "        print(categories[catid], output[catid])\n",
    "    # Write the result to a file.\n",
    "    with open(\"result.txt\", \"w\") as f:\n",
    "        for catid in top5_catid:\n",
    "            f.write(categories[catid] + \" \" + str(output[catid]) + \" \\r\")\n",
    "\n",
    "# Create main function to run inference.\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the categories from the classes file.\n",
    "    with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip() for s in f.readlines()]\n",
    "    \n",
    "    # Create Inference Session\n",
    "    session = onnxruntime.InferenceSession(\"mobilenet_v2_float.onnx\")\n",
    "\n",
    "    # Get image from the camera.\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3,640) # set Width\n",
    "    cap.set(4,480) # set Height\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, -1) # Flip camera vertically\n",
    "    cv2.imwrite('capture.jpg', frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Run inference\n",
    "    run_sample(session, 'capture.jpg', categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
