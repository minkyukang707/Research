{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Early fusion"
      ],
      "metadata": {
        "id": "FMKorLbmTCtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# CIFAR-10 데이터셋 다운로드\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "cifar_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# 데이터 프레임 생성\n",
        "random_data = pd.DataFrame(np.random.rand(50000, 8), columns=[f'col_{i}' for i in range(8)])\n",
        "\n",
        "# CIFAR-10 데이터셋에서 이미지의 픽셀 평균값 계산하여 데이터프레임에 추가\n",
        "pixel_means = []\n",
        "for i in range(len(cifar_dataset)):\n",
        "    img, _ = cifar_dataset[i]\n",
        "    pixel_mean = img.mean().item()  # 이미지의 픽셀 평균값 계산\n",
        "    pixel_means.append(pixel_mean)\n",
        "\n",
        "# 데이터프레임에 픽셀 평균값 열 추가\n",
        "random_data['pixel_mean'] = pixel_means\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = random_data\n",
        "# 맨 마지막 컬럼에 라벨 추가\n",
        "labels = []\n",
        "for i in range(10):\n",
        "    labels.extend([i] * 5000)\n",
        "\n",
        "df['label'] = labels\n",
        "\n",
        "# 학습 데이터셋과 테스트 데이터셋 나누기\n",
        "train_df = df[:40000]\n",
        "test_df = df[40000:]\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = torch.tensor(self.dataframe.iloc[idx, :-1].values, dtype=torch.float32)\n",
        "        target = torch.tensor(self.dataframe.iloc[idx, -1], dtype=torch.long)\n",
        "        return features, target\n",
        "\n",
        "# 데이터로더 생성\n",
        "train_dataset = CustomDataset(dataframe=train_df)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = CustomDataset(dataframe=test_df)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 다층 퍼셉트론(MLP) 모델 정의\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(9, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)  # 10개의 클래스에 대한 출력 레이어\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)  # 입력 데이터를 1차원으로 평평하게 만듦\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델 생성\n",
        "model = MLP()\n",
        "\n",
        "# 손실 함수 및 최적화 함수 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# F1 스코어 계산 함수 정의\n",
        "def calculate_f1_score(loader, model):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for features, targets in loader:\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(targets.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "    return f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# 모델 학습 및 테스트\n",
        "for epoch in range(5):  # 예시로 5 에포크만 학습\n",
        "    model.train()\n",
        "    for features, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # 매 에포크마다 테스트 데이터에 대한 F1 점수 출력\n",
        "    f1 = calculate_f1_score(test_loader, model)\n",
        "    print(f'Epoch {epoch+1}, Test F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "iDioF9hNTB8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--LEWaPjemaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}